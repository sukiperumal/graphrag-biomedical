{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.998s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.998s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"EPIRUBICIN\\\"\"\nDescription List: [\"\\\"Epirubicin is a chemotherapy drug used in the treatment of breast cancer.\\\"\", \"\\\"Epirubicin is a technology used in combination with docetaxel and trastuzumab in the treatment of breast cancer.\\\"\", \"\\\"epirubicin is a chemotherapy drug.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.964s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.964s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"NOAH STUDY\\\"\"\nDescription List: [\"\\\"NOAH study is a research study that investigated the efficacy of trastuzumab addition in breast cancer treatment.\\\"\", \"\\\"The NOAH study is a randomized phase 3 clinical trial.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.963s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.963s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"TRASTUZUMAB\\\"\"\nDescription List: [\"\", \"\\\"Trastuzumab is a humanized anti-HER2 monoclonal antibody that is part of the anti-HER2 backbone for HER2+ IBC.\\\"\", \"\\\"Trastuzumab is a medication used in breast cancer treatment.\\\"\", \"\\\"Trastuzumab is a medication used in cancer treatment.\\\"\", \"\\\"Trastuzumab is a medication used in the treatment of HER2+ IBC.\\\"\", \"\\\"Trastuzumab is a medication used in the treatment of HER2-positive breast cancer.\\\"\", \"\\\"Trastuzumab is a medication used in the treatment of breast cancer.\\\"\", \"\\\"Trastuzumab is a medication used to treat HER2+ breast cancer, especially in combination with pertuzumab.\\\"\", \"\\\"Trastuzumab is a medication used to treat HER2+ breast cancer.\\\"\", \"\\\"Trastuzumab is a medication used to treat HER2-positive breast cancer by blocking the HER2 protein.\\\"\", \"\\\"Trastuzumab is a targeted therapy approved for HER2+ disease, including IBC.\\\"\", \"\\\"Trastuzumab is a targeted therapy mentioned in the studies.\\\"\", \"\\\"Trastuzumab is a targeted therapy that targets HER2 receptors.\\\"\", \"\\\"Trastuzumab is a targeted therapy used to treat HER2-positive breast cancer.\\\"\", \"\\\"Trastuzumab is a technology used in combination with docetaxel and epirubicin in the treatment of breast cancer.\\\"\", \"\\\"Trastuzumab is a type of cancer treatment.\\\"\", \"\\\"Trastuzumab is a type of medication used in cancer treatment.\\\"\", \"\\\"trastuzumab is a HER2-targeting antibody.\\\"\", \"\\\"trastuzumab is a chemotherapy drug used in the NeoSphere clinical trial.\\\"\", \"\\\"trastuzumab is a chemotherapy drug.\\\"\", \"\\\"trastuzumab is a medication used in cancer treatment.\\\"\", \"\\\"trastuzumab is a monoclonal antibody that targets HER2.\\\"\", \"\\\"trastuzumab is a monoclonal antibody used in clinical trials.\\\"\", \"\\\"trastuzumab is a treatment option for IBC, used in combination with lapatinib and paclitaxel.\\\"\", \"\\\"trastuzumab is a treatment regimen for HER2+ breast cancer, often used in combination with pertuzumab.\\\"\", \"\\\"trastuzumab is a type of monoclonal antibody used to treat HER2+ breast cancer.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.963s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.963s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"ANTHRACYCLINE-CONTAINING REGIMEN\\\"\"\nDescription List: [\"\\\"Anthracycline-containing regimen is a treatment protocol for breast cancer.\\\"\", \"\\\"Anthracycline-containing regimen is a type of chemotherapy regimen used to treat breast cancer.\\\"\", \"\\\"Anthracycline-containing regimen is a type of chemotherapy that is used to treat HER2+ IBC.\\\"\", \"\\\"anthracycline-containing regimen is a type of treatment for HER2+ IBC.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.926s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.926s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"SYNERGISTIC COMBINATION\\\"\"\nDescription List: [\"\\\"Synergistic combination refers to the combination of trastuzumab and pertuzumab that has a greater effect than the sum of their individual effects.\\\"\", \"\\\"synergistic combination is a concept or marker that is associated with the combination of lapatinib and trastuzumab.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.922s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.922s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"PERTUZUMAB\\\"\"\nDescription List: [\"\\\"Pertuzumab is a humanized anti-HER2 monoclonal antibody that binds the HER2 receptor at a different epitope from trastuzumab.\\\"\", \"\\\"Pertuzumab is a medication used in cancer treatment.\\\"\", \"\\\"Pertuzumab is a medication used in the treatment of HER2+ IBC.\\\"\", \"\\\"Pertuzumab is a medication used in the treatment of HER2-positive breast cancer.\\\"\", \"\\\"Pertuzumab is a medication used in the treatment of breast cancer.\\\"\", \"\\\"Pertuzumab is a medication used to treat HER2+ breast cancer, especially in combination with trastuzumab.\\\"\", \"\\\"Pertuzumab is a medication used to treat HER2-positive breast cancer by blocking the HER2 protein.\\\"\", \"\\\"Pertuzumab is a medication.\\\"\", \"\\\"Pertuzumab is a monoclonal antibody used in breast cancer treatment.\\\"\", \"\\\"Pertuzumab is a targeted therapy that targets HER2 receptors.\\\"\", \"\\\"Pertuzumab is a type of antibody that binds to the HER2 receptor and induces antibody-dependent cell-mediated cytotoxicity.\\\"\", \"\\\"pertuzumab is a HER2-targeting antibody.\\\"\", \"\\\"pertuzumab is a chemotherapy drug used in the NeoSphere clinical trial.\\\"\", \"\\\"pertuzumab is a chemotherapy drug.\\\"\", \"\\\"pertuzumab is a monoclonal antibody used in clinical trials.\\\"\", \"\\\"pertuzumab is a treatment regimen for HER2+ breast cancer, often used in combination with T-DM1.\\\"\", \"\\\"pertuzumab is a type of monoclonal antibody used to treat HER2+ breast cancer.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.874s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.874s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"NEOSPHERE TRIAL\\\"\"\nDescription List: [\"\\\"NeoSphere trial is a clinical trial investigating the use of pertuzumab plus trastuzumab in combination with an anthracycline-containing regimen in patients with HER2-positive breast cancer.\\\"\", \"\\\"NeoSphere trial is a phase 2 randomized neoadjuvant trial that tested the combination of pertuzumab with trastuzumab in breast cancer patients.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.853s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.853s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"TRYPHAENA\\\"\"\nDescription List: [\"\", \"\\\"TRYPHAENA is a clinical trial investigating the safety and tolerability of dual anti-HER2 antibodies with different regimens.\\\"\", \"\\\"TRYPHAENA is a randomized phase 2 study that evaluated the safety and tolerability of dual anti-HER2 antibodies combined with NAC.\\\"\", \"\\\"TRYPHAENA is a randomized phase II cardiac safety study.\\\"\", \"\\\"TRYPHAENA is a study that reported pCR rates and DFS and OS at the 3-year follow-up.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.695s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.695s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"FEC\\\"\"\nDescription List: [\"\\\"FEC is a chemotherapy regimen mentioned in the studies.\\\"\", \"\\\"FEC is a chemotherapy regimen used in clinical trials.\\\"\", \"\\\"FEC is a chemotherapy regimen used in the NeoSphere clinical trial.\\\"\", \"\\\"FEC is a chemotherapy regimen, consisting of 5-fluorouracil, epirubicin, and cyclophosphamide.\\\"\", \"\\\"FEC is a regimen used in breast cancer treatment.\\\"\", \"\\\"FEC is a treatment regimen for breast cancer.\\\"\", \"\\\"FEC is a type of chemotherapy regimen used in the treatment of IBC.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.668s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.668s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"FEC REGIMEN\\\"\"\nDescription List: [\"\\\"FEC regimen is a chemotherapy treatment option for IBC patients.\\\"\", \"\\\"FEC regimen is a chemotherapy treatment protocol.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.581s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.581s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"TCHP\\\"\"\nDescription List: [\"\\\"TCHP is a chemotherapy treatment protocol.\\\"\", \"\\\"TCHP is a regimen of docetaxel, and carboplatin plus pertuzumab and trastuzumab used in cancer treatment.\\\"\", \"\\\"TCHP is a specific regimen for treating HER2+ IBC.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.462s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.462s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"OVERMOYER ET AL.\\\"\"\nDescription List: [\"\", \"\\\"Overmoyer et al. are researchers who reported the efficacy of neoadjuvant weekly paclitaxel combined with pertuzumab and trastuzumab.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.394s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.394s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"LAPATINIB\\\"\"\nDescription List: [\"\", \"\\\"Lapatinib is a drug used in combination with Pazopanib therapy.\\\"\", \"\\\"Lapatinib is a small-molecule tyrosine kinase inhibitor that blocks intracellular HER2 and EG.\\\"\", \"\\\"Lapatinib is a small-molecule tyrosine kinase inhibitor that blocks intracellular HER2 and EGFR signaling pathways.\\\"\", \"\\\"Lapatinib is an antibody-drug conjugate used in breast cancer treatment.\\\"\", \"\\\"lapatinib is a medication used in cancer treatment.\\\"\", \"\\\"lapatinib is a targeted therapy used to treat cancer.\\\"\", \"\\\"lapatinib is a treatment option for IBC, used in combination with NAC and trastuzumab.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.285s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.285s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"GEPARQUINTO\\\"\"\nDescription List: [\"\\\"GeparQuinto is a clinical trial studying the effectiveness of neoadjuvant chemotherapy with trastuzumab or lapatinib in patients with human epidermal growth factor receptor 2-positive breast cancer.\\\"\", \"\\\"GeparQuinto is a clinical trial that investigated lapatinib versus trastuzumab in combination with neoadjuvant chemotherapy.\\\"\", \"\\\"GeparQuinto is a randomized neoadjuvant phase 3 trial.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.276s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.276s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"THP\\\"\"\nDescription List: [\"\\\"THP is a chemotherapy treatment protocol.\\\"\", \"\\\"THP is a regimen of docetaxel plus trastuzumab and pertuzumab used in cancer treatment.\\\"\", \"\\\"THP is a specific regimen for treating HER2+ IBC.\\\"\", \"\\\"THP is an arm of the NeoSphere clinical trial that reported promising pCR rates.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.26s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.26s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"RESPONSE RATE\\\"\"\nDescription List: [\"\\\"Response rate refers to the percentage of participants who respond to a treatment.\\\"\", \"\\\"Response rate refers to the percentage of patients responding to treatment.\\\"\", \"\\\"response rate is a concept or marker that is associated with the effectiveness of treatment.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.131s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.131s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"PCR RATE\\\"\"\nDescription List: [\"\\\"pCR rate is a concept or marker that is associated with the effectiveness of treatment.\\\"\", \"\\\"pCR rate is a measure of the effectiveness of treatments for breast cancer.\\\"\", \"\\\"pCR rate is an endpoint in a clinical trial for IBC.\\\"\", \"\\\"pCR rate is the rate of patients who achieve a pathologic complete response to treatment.\\\"\", \"\\\"pCR rate refers to the percentage of patients achieving a pathologic complete response in breast cancer treatment.\\\"\", \"\\\"pCR rate refers to the percentage of patients achieving a pathologic complete response.\\\"\", \"\\\"pCR rate refers to the percentage of patients who achieve a pathologic complete response after treatment.\\\"\", \"\\\"pCR rate refers to the percentage of patients who achieve a pathologic complete response.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.091s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.091s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"T-DM1\\\"\"\nDescription List: [\"\", \"\\\"T-DM1 is a medication used in the treatment of breast cancer.\\\"\", \"\\\"T-DM1 is a treatment for HER2+ IBC cases without a pCR.\\\"\\\"T-DM1 is a type of antibody-drug conjugate used to treat HER2+ breast cancer.\\\"\", \"\\\"T-DM1 is an antibody-drug conjugate used in breast cancer treatment.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.028s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.028s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"TCHP REGIMEN\\\"\"\nDescription List: [\"\\\"TCHP regimen is a chemotherapy regimen that includes trastuzumab and pertuzumab.\\\"\", \"\\\"TCHP regimen is a type of chemotherapy regimen used to treat breast cancer.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.03s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.03s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"KRISTINE TRIAL\\\"\"\nDescription List: [\"\\\"KRISTINE trial is a randomized phase 3 trial evaluating neoadjuvant treatment with T-DM1 plus pertuzumab.\\\"\", \"\\\"The KRISTINE trial is a randomized phase 3 trial that evaluated the efficacy of T-DM1 plus pertuzumab in patients with HER2+ breast cancer.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 973ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 973ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"DIARRHEA\\\"\"\nDescription List: [\"\\\"Diarrhea is a common side effect of a medication.\\\"\", \"\\\"Diarrhea is a type of serious adverse event that is associated with chemotherapy.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 951ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 951ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"KATERINE TRIAL\\\"\"\nDescription List: [\"\\\"KATERINE trial is a clinical trial evaluating adjuvant therapy in patients with HER2+ breast cancer.\\\"\", \"\\\"KATERINE trial is a clinical trial investigating the use of adjuvant T-DM1 in HER2+ IBC cases without a pCR.\\\"\", \"\\\"KATERINE trial is a clinical trial that recommended adjuvant T-DM1 in HER2+ IBC cases without a pCR.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 524.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 524.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"S. CHAINITIKUN ET AL.\\\"\"\nDescription List: [\"\\\"S. Chainitikun et al. are the authors of the article published in the Journal of Advanced Research.\\\"\", \"\\\"S. Chainitikun et al. are the authors of the study.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 489ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 489ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"TRYPHAENA\\\"\"\nDescription List: [\"\", \"\\\"TRYPHAENA is a clinical trial investigating the safety and tolerability of dual anti-HER2 antibodies with different regimens.\\\"\", \"\\\"TRYPHAENA is a randomized phase 2 study that evaluated the safety and tolerability of dual anti-HER2 antibodies combined with NAC.\\\"\", \"\\\"TRYPHAENA is a randomized phase II cardiac safety study.\\\"\", \"\\\"TRYPHAENA is a study that reported pCR rates and DFS and OS at the 3-year follow-up.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 425.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 425.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"NERATINIB\\\"\"\nDescription List: [\"\\\"Neratinib is a medication used in adjuvant therapy for high-risk recurrent disease like IBC.\\\"\", \"\\\"Neratinib is a medication used in cancer treatment.\\\"\\\"Neratinib is offered as a treatment option.\\\"\", \"\\\"Neratinib is a medication used in the treatment of breast cancer.\\\"\", \"\\\"Neratinib is a medication used to treat HER2+ breast cancer, especially in high-risk situations.\\\"\", \"\\\"Neratinib is a treatment for HER2-positive breast cancer.\\\"\", \"\\\"neratinib is a chemotherapy drug.\\\"\", \"\\\"neratinib is a tyrosine kinase inhibitor used in clinical trials.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 290.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 290.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"FEC\\\"\"\nDescription List: [\"\\\"FEC is a chemotherapy regimen mentioned in the studies.\\\"\", \"\\\"FEC is a chemotherapy regimen used in clinical trials.\\\"\", \"\\\"FEC is a chemotherapy regimen used in the NeoSphere clinical trial.\\\"\", \"\\\"FEC is a chemotherapy regimen, consisting of 5-fluorouracil, epirubicin, and cyclophosphamide.\\\"\", \"\\\"FEC is a regimen used in breast cancer treatment.\\\"\", \"\\\"FEC is a treatment regimen for breast cancer.\\\"\", \"\\\"FEC is a type of chemotherapy regimen used in the treatment of IBC.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 284.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 284.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"ANTHRACYCLINE-CONTAINING REGIMEN\\\"\"\nDescription List: [\"\\\"Anthracycline-containing regimen is a treatment protocol for breast cancer.\\\"\", \"\\\"Anthracycline-containing regimen is a type of chemotherapy regimen used to treat breast cancer.\\\"\", \"\\\"Anthracycline-containing regimen is a type of chemotherapy that is used to treat HER2+ IBC.\\\"\", \"\\\"anthracycline-containing regimen is a type of treatment for HER2+ IBC.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 199ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 199ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"SYNERGISTIC COMBINATION\\\"\"\nDescription List: [\"\\\"Synergistic combination refers to the combination of trastuzumab and pertuzumab that has a greater effect than the sum of their individual effects.\\\"\", \"\\\"synergistic combination is a concept or marker that is associated with the combination of lapatinib and trastuzumab.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 76.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 76.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"TRASTUZUMAB\\\"\"\nDescription List: [\"\", \"\\\"Trastuzumab is a humanized anti-HER2 monoclonal antibody that is part of the anti-HER2 backbone for HER2+ IBC.\\\"\", \"\\\"Trastuzumab is a medication used in breast cancer treatment.\\\"\", \"\\\"Trastuzumab is a medication used in cancer treatment.\\\"\", \"\\\"Trastuzumab is a medication used in the treatment of HER2+ IBC.\\\"\", \"\\\"Trastuzumab is a medication used in the treatment of HER2-positive breast cancer.\\\"\", \"\\\"Trastuzumab is a medication used in the treatment of breast cancer.\\\"\", \"\\\"Trastuzumab is a medication used to treat HER2+ breast cancer, especially in combination with pertuzumab.\\\"\", \"\\\"Trastuzumab is a medication used to treat HER2+ breast cancer.\\\"\", \"\\\"Trastuzumab is a medication used to treat HER2-positive breast cancer by blocking the HER2 protein.\\\"\", \"\\\"Trastuzumab is a targeted therapy approved for HER2+ disease, including IBC.\\\"\", \"\\\"Trastuzumab is a targeted therapy mentioned in the studies.\\\"\", \"\\\"Trastuzumab is a targeted therapy that targets HER2 receptors.\\\"\", \"\\\"Trastuzumab is a targeted therapy used to treat HER2-positive breast cancer.\\\"\", \"\\\"Trastuzumab is a technology used in combination with docetaxel and epirubicin in the treatment of breast cancer.\\\"\", \"\\\"Trastuzumab is a type of cancer treatment.\\\"\", \"\\\"Trastuzumab is a type of medication used in cancer treatment.\\\"\", \"\\\"trastuzumab is a HER2-targeting antibody.\\\"\", \"\\\"trastuzumab is a chemotherapy drug used in the NeoSphere clinical trial.\\\"\", \"\\\"trastuzumab is a chemotherapy drug.\\\"\", \"\\\"trastuzumab is a medication used in cancer treatment.\\\"\", \"\\\"trastuzumab is a monoclonal antibody that targets HER2.\\\"\", \"\\\"trastuzumab is a monoclonal antibody used in clinical trials.\\\"\", \"\\\"trastuzumab is a treatment option for IBC, used in combination with lapatinib and paclitaxel.\\\"\", \"\\\"trastuzumab is a treatment regimen for HER2+ breast cancer, often used in combination with pertuzumab.\\\"\", \"\\\"trastuzumab is a type of monoclonal antibody used to treat HER2+ breast cancer.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 4ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 4ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"FEC REGIMEN\\\"\"\nDescription List: [\"\\\"FEC regimen is a chemotherapy treatment option for IBC patients.\\\"\", \"\\\"FEC regimen is a chemotherapy treatment protocol.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 2ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 2ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"NOAH STUDY\\\"\"\nDescription List: [\"\\\"NOAH study is a research study that investigated the efficacy of trastuzumab addition in breast cancer treatment.\\\"\", \"\\\"The NOAH study is a randomized phase 3 clinical trial.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.901s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.901s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"NEOSPHERE TRIAL\\\"\"\nDescription List: [\"\\\"NeoSphere trial is a clinical trial investigating the use of pertuzumab plus trastuzumab in combination with an anthracycline-containing regimen in patients with HER2-positive breast cancer.\\\"\", \"\\\"NeoSphere trial is a phase 2 randomized neoadjuvant trial that tested the combination of pertuzumab with trastuzumab in breast cancer patients.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.887s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.887s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"PERTUZUMAB\\\"\"\nDescription List: [\"\\\"Pertuzumab is a humanized anti-HER2 monoclonal antibody that binds the HER2 receptor at a different epitope from trastuzumab.\\\"\", \"\\\"Pertuzumab is a medication used in cancer treatment.\\\"\", \"\\\"Pertuzumab is a medication used in the treatment of HER2+ IBC.\\\"\", \"\\\"Pertuzumab is a medication used in the treatment of HER2-positive breast cancer.\\\"\", \"\\\"Pertuzumab is a medication used in the treatment of breast cancer.\\\"\", \"\\\"Pertuzumab is a medication used to treat HER2+ breast cancer, especially in combination with trastuzumab.\\\"\", \"\\\"Pertuzumab is a medication used to treat HER2-positive breast cancer by blocking the HER2 protein.\\\"\", \"\\\"Pertuzumab is a medication.\\\"\", \"\\\"Pertuzumab is a monoclonal antibody used in breast cancer treatment.\\\"\", \"\\\"Pertuzumab is a targeted therapy that targets HER2 receptors.\\\"\", \"\\\"Pertuzumab is a type of antibody that binds to the HER2 receptor and induces antibody-dependent cell-mediated cytotoxicity.\\\"\", \"\\\"pertuzumab is a HER2-targeting antibody.\\\"\", \"\\\"pertuzumab is a chemotherapy drug used in the NeoSphere clinical trial.\\\"\", \"\\\"pertuzumab is a chemotherapy drug.\\\"\", \"\\\"pertuzumab is a monoclonal antibody used in clinical trials.\\\"\", \"\\\"pertuzumab is a treatment regimen for HER2+ breast cancer, often used in combination with T-DM1.\\\"\", \"\\\"pertuzumab is a type of monoclonal antibody used to treat HER2+ breast cancer.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.815s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.815s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"OVERMOYER ET AL.\\\"\"\nDescription List: [\"\", \"\\\"Overmoyer et al. are researchers who reported the efficacy of neoadjuvant weekly paclitaxel combined with pertuzumab and trastuzumab.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.816s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.816s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"T-DM1\\\"\"\nDescription List: [\"\", \"\\\"T-DM1 is a medication used in the treatment of breast cancer.\\\"\", \"\\\"T-DM1 is a treatment for HER2+ IBC cases without a pCR.\\\"\\\"T-DM1 is a type of antibody-drug conjugate used to treat HER2+ breast cancer.\\\"\", \"\\\"T-DM1 is an antibody-drug conjugate used in breast cancer treatment.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.743s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.743s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"PCR RATE\\\"\"\nDescription List: [\"\\\"pCR rate is a concept or marker that is associated with the effectiveness of treatment.\\\"\", \"\\\"pCR rate is a measure of the effectiveness of treatments for breast cancer.\\\"\", \"\\\"pCR rate is an endpoint in a clinical trial for IBC.\\\"\", \"\\\"pCR rate is the rate of patients who achieve a pathologic complete response to treatment.\\\"\", \"\\\"pCR rate refers to the percentage of patients achieving a pathologic complete response in breast cancer treatment.\\\"\", \"\\\"pCR rate refers to the percentage of patients achieving a pathologic complete response.\\\"\", \"\\\"pCR rate refers to the percentage of patients who achieve a pathologic complete response after treatment.\\\"\", \"\\\"pCR rate refers to the percentage of patients who achieve a pathologic complete response.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.7s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.7s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"THP\\\"\"\nDescription List: [\"\\\"THP is a chemotherapy treatment protocol.\\\"\", \"\\\"THP is a regimen of docetaxel plus trastuzumab and pertuzumab used in cancer treatment.\\\"\", \"\\\"THP is a specific regimen for treating HER2+ IBC.\\\"\", \"\\\"THP is an arm of the NeoSphere clinical trial that reported promising pCR rates.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.695s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.695s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"TCHP\\\"\"\nDescription List: [\"\\\"TCHP is a chemotherapy treatment protocol.\\\"\", \"\\\"TCHP is a regimen of docetaxel, and carboplatin plus pertuzumab and trastuzumab used in cancer treatment.\\\"\", \"\\\"TCHP is a specific regimen for treating HER2+ IBC.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.573s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.573s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"LAPATINIB\\\"\"\nDescription List: [\"\", \"\\\"Lapatinib is a drug used in combination with Pazopanib therapy.\\\"\", \"\\\"Lapatinib is a small-molecule tyrosine kinase inhibitor that blocks intracellular HER2 and EG.\\\"\", \"\\\"Lapatinib is a small-molecule tyrosine kinase inhibitor that blocks intracellular HER2 and EGFR signaling pathways.\\\"\", \"\\\"Lapatinib is an antibody-drug conjugate used in breast cancer treatment.\\\"\", \"\\\"lapatinib is a medication used in cancer treatment.\\\"\", \"\\\"lapatinib is a targeted therapy used to treat cancer.\\\"\", \"\\\"lapatinib is a treatment option for IBC, used in combination with NAC and trastuzumab.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.584s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.584s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"TCHP REGIMEN\\\"\"\nDescription List: [\"\\\"TCHP regimen is a chemotherapy regimen that includes trastuzumab and pertuzumab.\\\"\", \"\\\"TCHP regimen is a type of chemotherapy regimen used to treat breast cancer.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.539s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.539s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"GEPARQUINTO\\\"\"\nDescription List: [\"\\\"GeparQuinto is a clinical trial studying the effectiveness of neoadjuvant chemotherapy with trastuzumab or lapatinib in patients with human epidermal growth factor receptor 2-positive breast cancer.\\\"\", \"\\\"GeparQuinto is a clinical trial that investigated lapatinib versus trastuzumab in combination with neoadjuvant chemotherapy.\\\"\", \"\\\"GeparQuinto is a randomized neoadjuvant phase 3 trial.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.326s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.326s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"KATERINE TRIAL\\\"\"\nDescription List: [\"\\\"KATERINE trial is a clinical trial evaluating adjuvant therapy in patients with HER2+ breast cancer.\\\"\", \"\\\"KATERINE trial is a clinical trial investigating the use of adjuvant T-DM1 in HER2+ IBC cases without a pCR.\\\"\", \"\\\"KATERINE trial is a clinical trial that recommended adjuvant T-DM1 in HER2+ IBC cases without a pCR.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.218999999s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.218999999s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"DIARRHEA\\\"\"\nDescription List: [\"\\\"Diarrhea is a common side effect of a medication.\\\"\", \"\\\"Diarrhea is a type of serious adverse event that is associated with chemotherapy.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.084s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.084s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"RESPONSE RATE\\\"\"\nDescription List: [\"\\\"Response rate refers to the percentage of participants who respond to a treatment.\\\"\", \"\\\"Response rate refers to the percentage of patients responding to treatment.\\\"\", \"\\\"response rate is a concept or marker that is associated with the effectiveness of treatment.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.011s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.011s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"S. CHAINITIKUN ET AL.\\\"\"\nDescription List: [\"\\\"S. Chainitikun et al. are the authors of the article published in the Journal of Advanced Research.\\\"\", \"\\\"S. Chainitikun et al. are the authors of the study.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 975ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 975ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"NERATINIB\\\"\"\nDescription List: [\"\\\"Neratinib is a medication used in adjuvant therapy for high-risk recurrent disease like IBC.\\\"\", \"\\\"Neratinib is a medication used in cancer treatment.\\\"\\\"Neratinib is offered as a treatment option.\\\"\", \"\\\"Neratinib is a medication used in the treatment of breast cancer.\\\"\", \"\\\"Neratinib is a medication used to treat HER2+ breast cancer, especially in high-risk situations.\\\"\", \"\\\"Neratinib is a treatment for HER2-positive breast cancer.\\\"\", \"\\\"neratinib is a chemotherapy drug.\\\"\", \"\\\"neratinib is a tyrosine kinase inhibitor used in clinical trials.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 939ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 939ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"KRISTINE TRIAL\\\"\"\nDescription List: [\"\\\"KRISTINE trial is a randomized phase 3 trial evaluating neoadjuvant treatment with T-DM1 plus pertuzumab.\\\"\", \"\\\"The KRISTINE trial is a randomized phase 3 trial that evaluated the efficacy of T-DM1 plus pertuzumab in patients with HER2+ breast cancer.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 352ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 352ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"EXTENET\\\"\"\nDescription List: [\"\\\"ExteNET is a clinical trial for HER2-positive breast cancer.\\\"\", \"\\\"ExteNET is a clinical trial that studied the use of neratinib in breast cancer patients.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 197.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 197.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"TRYPHAENA\\\"\"\nDescription List: [\"\", \"\\\"TRYPHAENA is a clinical trial investigating the safety and tolerability of dual anti-HER2 antibodies with different regimens.\\\"\", \"\\\"TRYPHAENA is a randomized phase 2 study that evaluated the safety and tolerability of dual anti-HER2 antibodies combined with NAC.\\\"\", \"\\\"TRYPHAENA is a randomized phase II cardiac safety study.\\\"\", \"\\\"TRYPHAENA is a study that reported pCR rates and DFS and OS at the 3-year follow-up.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 12ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 12ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"BEVACIZUMAB\\\"\"\nDescription List: [\"\", \"\\\"Bevacizumab is a medication used in combination with chemotherapy to treat breast cancer.\\\"\", \"\\\"Bevacizumab is a monoclonal antibody against VEGF, used in combination with taxane-based chemotherapy to inhibit tumor growth and metastasis.\\\"\", \"\\\"Bevacizumab is a targeted therapy mentioned in the studies.\\\"\", \"\\\"Bevacizumab is a targeted therapy used in combination with chemotherapy for IBC patients.\\\"\", \"\\\"Bevacizumab is a technology used in the treatment of breast cancer and was studied in the presented research.\\\"\", \"\\\"Bevacizumab is a type of cancer treatment.\\\"\", \"\\\"Bevacizumab is a type of medication used in cancer treatment.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.903s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.903s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"FEC\\\"\"\nDescription List: [\"\\\"FEC is a chemotherapy regimen mentioned in the studies.\\\"\", \"\\\"FEC is a chemotherapy regimen used in clinical trials.\\\"\", \"\\\"FEC is a chemotherapy regimen used in the NeoSphere clinical trial.\\\"\", \"\\\"FEC is a chemotherapy regimen, consisting of 5-fluorouracil, epirubicin, and cyclophosphamide.\\\"\", \"\\\"FEC is a regimen used in breast cancer treatment.\\\"\", \"\\\"FEC is a treatment regimen for breast cancer.\\\"\", \"\\\"FEC is a type of chemotherapy regimen used in the treatment of IBC.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.691s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.691s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"NOAH STUDY\\\"\"\nDescription List: [\"\\\"NOAH study is a research study that investigated the efficacy of trastuzumab addition in breast cancer treatment.\\\"\", \"\\\"The NOAH study is a randomized phase 3 clinical trial.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.673s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.673s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"T-DM1\\\"\"\nDescription List: [\"\", \"\\\"T-DM1 is a medication used in the treatment of breast cancer.\\\"\", \"\\\"T-DM1 is a treatment for HER2+ IBC cases without a pCR.\\\"\\\"T-DM1 is a type of antibody-drug conjugate used to treat HER2+ breast cancer.\\\"\", \"\\\"T-DM1 is an antibody-drug conjugate used in breast cancer treatment.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.668s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.668s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"OVERMOYER ET AL.\\\"\"\nDescription List: [\"\", \"\\\"Overmoyer et al. are researchers who reported the efficacy of neoadjuvant weekly paclitaxel combined with pertuzumab and trastuzumab.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.663s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.663s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"ANTHRACYCLINE-CONTAINING REGIMEN\\\"\"\nDescription List: [\"\\\"Anthracycline-containing regimen is a treatment protocol for breast cancer.\\\"\", \"\\\"Anthracycline-containing regimen is a type of chemotherapy regimen used to treat breast cancer.\\\"\", \"\\\"Anthracycline-containing regimen is a type of chemotherapy that is used to treat HER2+ IBC.\\\"\", \"\\\"anthracycline-containing regimen is a type of treatment for HER2+ IBC.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.567s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.567s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"THP\\\"\"\nDescription List: [\"\\\"THP is a chemotherapy treatment protocol.\\\"\", \"\\\"THP is a regimen of docetaxel plus trastuzumab and pertuzumab used in cancer treatment.\\\"\", \"\\\"THP is a specific regimen for treating HER2+ IBC.\\\"\", \"\\\"THP is an arm of the NeoSphere clinical trial that reported promising pCR rates.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.556s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.556s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"FEC REGIMEN\\\"\"\nDescription List: [\"\\\"FEC regimen is a chemotherapy treatment option for IBC patients.\\\"\", \"\\\"FEC regimen is a chemotherapy treatment protocol.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.551s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.551s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"TCHP\\\"\"\nDescription List: [\"\\\"TCHP is a chemotherapy treatment protocol.\\\"\", \"\\\"TCHP is a regimen of docetaxel, and carboplatin plus pertuzumab and trastuzumab used in cancer treatment.\\\"\", \"\\\"TCHP is a specific regimen for treating HER2+ IBC.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.546s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.546s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"SYNERGISTIC COMBINATION\\\"\"\nDescription List: [\"\\\"Synergistic combination refers to the combination of trastuzumab and pertuzumab that has a greater effect than the sum of their individual effects.\\\"\", \"\\\"synergistic combination is a concept or marker that is associated with the combination of lapatinib and trastuzumab.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.288s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.288s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"NEOSPHERE TRIAL\\\"\"\nDescription List: [\"\\\"NeoSphere trial is a clinical trial investigating the use of pertuzumab plus trastuzumab in combination with an anthracycline-containing regimen in patients with HER2-positive breast cancer.\\\"\", \"\\\"NeoSphere trial is a phase 2 randomized neoadjuvant trial that tested the combination of pertuzumab with trastuzumab in breast cancer patients.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.274s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.274s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"PERTUZUMAB\\\"\"\nDescription List: [\"\\\"Pertuzumab is a humanized anti-HER2 monoclonal antibody that binds the HER2 receptor at a different epitope from trastuzumab.\\\"\", \"\\\"Pertuzumab is a medication used in cancer treatment.\\\"\", \"\\\"Pertuzumab is a medication used in the treatment of HER2+ IBC.\\\"\", \"\\\"Pertuzumab is a medication used in the treatment of HER2-positive breast cancer.\\\"\", \"\\\"Pertuzumab is a medication used in the treatment of breast cancer.\\\"\", \"\\\"Pertuzumab is a medication used to treat HER2+ breast cancer, especially in combination with trastuzumab.\\\"\", \"\\\"Pertuzumab is a medication used to treat HER2-positive breast cancer by blocking the HER2 protein.\\\"\", \"\\\"Pertuzumab is a medication.\\\"\", \"\\\"Pertuzumab is a monoclonal antibody used in breast cancer treatment.\\\"\", \"\\\"Pertuzumab is a targeted therapy that targets HER2 receptors.\\\"\", \"\\\"Pertuzumab is a type of antibody that binds to the HER2 receptor and induces antibody-dependent cell-mediated cytotoxicity.\\\"\", \"\\\"pertuzumab is a HER2-targeting antibody.\\\"\", \"\\\"pertuzumab is a chemotherapy drug used in the NeoSphere clinical trial.\\\"\", \"\\\"pertuzumab is a chemotherapy drug.\\\"\", \"\\\"pertuzumab is a monoclonal antibody used in clinical trials.\\\"\", \"\\\"pertuzumab is a treatment regimen for HER2+ breast cancer, often used in combination with T-DM1.\\\"\", \"\\\"pertuzumab is a type of monoclonal antibody used to treat HER2+ breast cancer.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.216s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.216s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"EXTENET\\\"\"\nDescription List: [\"\\\"ExteNET is a clinical trial for HER2-positive breast cancer.\\\"\", \"\\\"ExteNET is a clinical trial that studied the use of neratinib in breast cancer patients.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.101s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.101s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"PCR RATE\\\"\"\nDescription List: [\"\\\"pCR rate is a concept or marker that is associated with the effectiveness of treatment.\\\"\", \"\\\"pCR rate is a measure of the effectiveness of treatments for breast cancer.\\\"\", \"\\\"pCR rate is an endpoint in a clinical trial for IBC.\\\"\", \"\\\"pCR rate is the rate of patients who achieve a pathologic complete response to treatment.\\\"\", \"\\\"pCR rate refers to the percentage of patients achieving a pathologic complete response in breast cancer treatment.\\\"\", \"\\\"pCR rate refers to the percentage of patients achieving a pathologic complete response.\\\"\", \"\\\"pCR rate refers to the percentage of patients who achieve a pathologic complete response after treatment.\\\"\", \"\\\"pCR rate refers to the percentage of patients who achieve a pathologic complete response.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.046s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.046s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"RESPONSE RATE\\\"\"\nDescription List: [\"\\\"Response rate refers to the percentage of participants who respond to a treatment.\\\"\", \"\\\"Response rate refers to the percentage of patients responding to treatment.\\\"\", \"\\\"response rate is a concept or marker that is associated with the effectiveness of treatment.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.038s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.038s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"GEPARQUINTO\\\"\"\nDescription List: [\"\\\"GeparQuinto is a clinical trial studying the effectiveness of neoadjuvant chemotherapy with trastuzumab or lapatinib in patients with human epidermal growth factor receptor 2-positive breast cancer.\\\"\", \"\\\"GeparQuinto is a clinical trial that investigated lapatinib versus trastuzumab in combination with neoadjuvant chemotherapy.\\\"\", \"\\\"GeparQuinto is a randomized neoadjuvant phase 3 trial.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 960ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 960ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"LAPATINIB\\\"\"\nDescription List: [\"\", \"\\\"Lapatinib is a drug used in combination with Pazopanib therapy.\\\"\", \"\\\"Lapatinib is a small-molecule tyrosine kinase inhibitor that blocks intracellular HER2 and EG.\\\"\", \"\\\"Lapatinib is a small-molecule tyrosine kinase inhibitor that blocks intracellular HER2 and EGFR signaling pathways.\\\"\", \"\\\"Lapatinib is an antibody-drug conjugate used in breast cancer treatment.\\\"\", \"\\\"lapatinib is a medication used in cancer treatment.\\\"\", \"\\\"lapatinib is a targeted therapy used to treat cancer.\\\"\", \"\\\"lapatinib is a treatment option for IBC, used in combination with NAC and trastuzumab.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 958ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 958ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"TCHP REGIMEN\\\"\"\nDescription List: [\"\\\"TCHP regimen is a chemotherapy regimen that includes trastuzumab and pertuzumab.\\\"\", \"\\\"TCHP regimen is a type of chemotherapy regimen used to treat breast cancer.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 778.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 778.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"KATERINE TRIAL\\\"\"\nDescription List: [\"\\\"KATERINE trial is a clinical trial evaluating adjuvant therapy in patients with HER2+ breast cancer.\\\"\", \"\\\"KATERINE trial is a clinical trial investigating the use of adjuvant T-DM1 in HER2+ IBC cases without a pCR.\\\"\", \"\\\"KATERINE trial is a clinical trial that recommended adjuvant T-DM1 in HER2+ IBC cases without a pCR.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 729ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 729ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"DIARRHEA\\\"\"\nDescription List: [\"\\\"Diarrhea is a common side effect of a medication.\\\"\", \"\\\"Diarrhea is a type of serious adverse event that is associated with chemotherapy.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 524.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 524.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"BEVACIZUMAB\\\"\"\nDescription List: [\"\", \"\\\"Bevacizumab is a medication used in combination with chemotherapy to treat breast cancer.\\\"\", \"\\\"Bevacizumab is a monoclonal antibody against VEGF, used in combination with taxane-based chemotherapy to inhibit tumor growth and metastasis.\\\"\", \"\\\"Bevacizumab is a targeted therapy mentioned in the studies.\\\"\", \"\\\"Bevacizumab is a targeted therapy used in combination with chemotherapy for IBC patients.\\\"\", \"\\\"Bevacizumab is a technology used in the treatment of breast cancer and was studied in the presented research.\\\"\", \"\\\"Bevacizumab is a type of cancer treatment.\\\"\", \"\\\"Bevacizumab is a type of medication used in cancer treatment.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 526ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 526ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"TAXANE-BASED CHEMOTHERAPY\\\"\"\nDescription List: [\"\\\"Taxane-based Chemotherapy is a type of chemotherapy used in the treatment of IBC.\\\"\", \"\\\"Taxane-based chemotherapy is a type of chemotherapy used in the treatment of IBC.\\\"\", \"\\\"Taxane-based chemotherapy is used in combination with Bevacizumab to inhibit tumor growth and metastasis.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 405.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 405.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"S. CHAINITIKUN ET AL.\\\"\"\nDescription List: [\"\\\"S. Chainitikun et al. are the authors of the article published in the Journal of Advanced Research.\\\"\", \"\\\"S. Chainitikun et al. are the authors of the study.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 183.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 183.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"NERATINIB\\\"\"\nDescription List: [\"\\\"Neratinib is a medication used in adjuvant therapy for high-risk recurrent disease like IBC.\\\"\", \"\\\"Neratinib is a medication used in cancer treatment.\\\"\\\"Neratinib is offered as a treatment option.\\\"\", \"\\\"Neratinib is a medication used in the treatment of breast cancer.\\\"\", \"\\\"Neratinib is a medication used to treat HER2+ breast cancer, especially in high-risk situations.\\\"\", \"\\\"Neratinib is a treatment for HER2-positive breast cancer.\\\"\", \"\\\"neratinib is a chemotherapy drug.\\\"\", \"\\\"neratinib is a tyrosine kinase inhibitor used in clinical trials.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 100ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 100ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"KRISTINE TRIAL\\\"\"\nDescription List: [\"\\\"KRISTINE trial is a randomized phase 3 trial evaluating neoadjuvant treatment with T-DM1 plus pertuzumab.\\\"\", \"\\\"The KRISTINE trial is a randomized phase 3 trial that evaluated the efficacy of T-DM1 plus pertuzumab in patients with HER2+ breast cancer.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.905s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.905s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"TAXANE-BASED CHEMOTHERAPY\\\"\"\nDescription List: [\"\\\"Taxane-based Chemotherapy is a type of chemotherapy used in the treatment of IBC.\\\"\", \"\\\"Taxane-based chemotherapy is a type of chemotherapy used in the treatment of IBC.\\\"\", \"\\\"Taxane-based chemotherapy is used in combination with Bevacizumab to inhibit tumor growth and metastasis.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.663s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.663s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"BEVACIZUMAB\\\"\"\nDescription List: [\"\", \"\\\"Bevacizumab is a medication used in combination with chemotherapy to treat breast cancer.\\\"\", \"\\\"Bevacizumab is a monoclonal antibody against VEGF, used in combination with taxane-based chemotherapy to inhibit tumor growth and metastasis.\\\"\", \"\\\"Bevacizumab is a targeted therapy mentioned in the studies.\\\"\", \"\\\"Bevacizumab is a targeted therapy used in combination with chemotherapy for IBC patients.\\\"\", \"\\\"Bevacizumab is a technology used in the treatment of breast cancer and was studied in the presented research.\\\"\", \"\\\"Bevacizumab is a type of cancer treatment.\\\"\", \"\\\"Bevacizumab is a type of medication used in cancer treatment.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.659s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.659s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"BEVERLY-1\\\"\"\nDescription List: [\"\\\"BEVERLY-1 is a clinical trial for breast cancer treatment.\\\"\", \"\\\"BEVERLY-1 is a single-arm phase 2 study that evaluated the pCR rate in non-metastatic IBC patients with HER2- disease.\\\"\", \"\\\"BEVERLY-1 is a study evaluating the pCR rate in non-metastatic IBC patients with HER2- disease.\\\"\", \"\\\"BEVERLY-1 is a study mentioned in the text.\\\"\", \"\\\"BEVERLY-1 is a study that reported on the use of circulating tumor cells as a biomarker for treatment effectiveness.\\\"\", \"\\\"BEVERLY-1 is an event where a study on bevacizumab plus neoadjuvant chemotherapy in patients with HER2-negative inflammatory breast cancer was conducted.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.35s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.35s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"TRYPHAENA\\\"\"\nDescription List: [\"\", \"\\\"TRYPHAENA is a clinical trial investigating the safety and tolerability of dual anti-HER2 antibodies with different regimens.\\\"\", \"\\\"TRYPHAENA is a randomized phase 2 study that evaluated the safety and tolerability of dual anti-HER2 antibodies combined with NAC.\\\"\", \"\\\"TRYPHAENA is a randomized phase II cardiac safety study.\\\"\", \"\\\"TRYPHAENA is a study that reported pCR rates and DFS and OS at the 3-year follow-up.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 865ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 865ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"T-DM1\\\"\"\nDescription List: [\"\", \"\\\"T-DM1 is a medication used in the treatment of breast cancer.\\\"\", \"\\\"T-DM1 is a treatment for HER2+ IBC cases without a pCR.\\\"\\\"T-DM1 is a type of antibody-drug conjugate used to treat HER2+ breast cancer.\\\"\", \"\\\"T-DM1 is an antibody-drug conjugate used in breast cancer treatment.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 864ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 864ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"FEC\\\"\"\nDescription List: [\"\\\"FEC is a chemotherapy regimen mentioned in the studies.\\\"\", \"\\\"FEC is a chemotherapy regimen used in clinical trials.\\\"\", \"\\\"FEC is a chemotherapy regimen used in the NeoSphere clinical trial.\\\"\", \"\\\"FEC is a chemotherapy regimen, consisting of 5-fluorouracil, epirubicin, and cyclophosphamide.\\\"\", \"\\\"FEC is a regimen used in breast cancer treatment.\\\"\", \"\\\"FEC is a treatment regimen for breast cancer.\\\"\", \"\\\"FEC is a type of chemotherapy regimen used in the treatment of IBC.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 818ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 818ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"ANTHRACYCLINE-CONTAINING REGIMEN\\\"\"\nDescription List: [\"\\\"Anthracycline-containing regimen is a treatment protocol for breast cancer.\\\"\", \"\\\"Anthracycline-containing regimen is a type of chemotherapy regimen used to treat breast cancer.\\\"\", \"\\\"Anthracycline-containing regimen is a type of chemotherapy that is used to treat HER2+ IBC.\\\"\", \"\\\"anthracycline-containing regimen is a type of treatment for HER2+ IBC.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 706ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 706ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"TCHP\\\"\"\nDescription List: [\"\\\"TCHP is a chemotherapy treatment protocol.\\\"\", \"\\\"TCHP is a regimen of docetaxel, and carboplatin plus pertuzumab and trastuzumab used in cancer treatment.\\\"\", \"\\\"TCHP is a specific regimen for treating HER2+ IBC.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 559ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 559ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"FEC REGIMEN\\\"\"\nDescription List: [\"\\\"FEC regimen is a chemotherapy treatment option for IBC patients.\\\"\", \"\\\"FEC regimen is a chemotherapy treatment protocol.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 336.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 336.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"THP\\\"\"\nDescription List: [\"\\\"THP is a chemotherapy treatment protocol.\\\"\", \"\\\"THP is a regimen of docetaxel plus trastuzumab and pertuzumab used in cancer treatment.\\\"\", \"\\\"THP is a specific regimen for treating HER2+ IBC.\\\"\", \"\\\"THP is an arm of the NeoSphere clinical trial that reported promising pCR rates.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 155.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 155.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"NEOSPHERE TRIAL\\\"\"\nDescription List: [\"\\\"NeoSphere trial is a clinical trial investigating the use of pertuzumab plus trastuzumab in combination with an anthracycline-containing regimen in patients with HER2-positive breast cancer.\\\"\", \"\\\"NeoSphere trial is a phase 2 randomized neoadjuvant trial that tested the combination of pertuzumab with trastuzumab in breast cancer patients.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 112.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 112.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"NOAH STUDY\\\"\"\nDescription List: [\"\\\"NOAH study is a research study that investigated the efficacy of trastuzumab addition in breast cancer treatment.\\\"\", \"\\\"The NOAH study is a randomized phase 3 clinical trial.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 68.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 68.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"PERTUZUMAB\\\"\"\nDescription List: [\"\\\"Pertuzumab is a humanized anti-HER2 monoclonal antibody that binds the HER2 receptor at a different epitope from trastuzumab.\\\"\", \"\\\"Pertuzumab is a medication used in cancer treatment.\\\"\", \"\\\"Pertuzumab is a medication used in the treatment of HER2+ IBC.\\\"\", \"\\\"Pertuzumab is a medication used in the treatment of HER2-positive breast cancer.\\\"\", \"\\\"Pertuzumab is a medication used in the treatment of breast cancer.\\\"\", \"\\\"Pertuzumab is a medication used to treat HER2+ breast cancer, especially in combination with trastuzumab.\\\"\", \"\\\"Pertuzumab is a medication used to treat HER2-positive breast cancer by blocking the HER2 protein.\\\"\", \"\\\"Pertuzumab is a medication.\\\"\", \"\\\"Pertuzumab is a monoclonal antibody used in breast cancer treatment.\\\"\", \"\\\"Pertuzumab is a targeted therapy that targets HER2 receptors.\\\"\", \"\\\"Pertuzumab is a type of antibody that binds to the HER2 receptor and induces antibody-dependent cell-mediated cytotoxicity.\\\"\", \"\\\"pertuzumab is a HER2-targeting antibody.\\\"\", \"\\\"pertuzumab is a chemotherapy drug used in the NeoSphere clinical trial.\\\"\", \"\\\"pertuzumab is a chemotherapy drug.\\\"\", \"\\\"pertuzumab is a monoclonal antibody used in clinical trials.\\\"\", \"\\\"pertuzumab is a treatment regimen for HER2+ breast cancer, often used in combination with T-DM1.\\\"\", \"\\\"pertuzumab is a type of monoclonal antibody used to treat HER2+ breast cancer.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 12ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 12ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"SYNERGISTIC COMBINATION\\\"\"\nDescription List: [\"\\\"Synergistic combination refers to the combination of trastuzumab and pertuzumab that has a greater effect than the sum of their individual effects.\\\"\", \"\\\"synergistic combination is a concept or marker that is associated with the combination of lapatinib and trastuzumab.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 10.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 10.999999ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"PCR RATE\\\"\"\nDescription List: [\"\\\"pCR rate is a concept or marker that is associated with the effectiveness of treatment.\\\"\", \"\\\"pCR rate is a measure of the effectiveness of treatments for breast cancer.\\\"\", \"\\\"pCR rate is an endpoint in a clinical trial for IBC.\\\"\", \"\\\"pCR rate is the rate of patients who achieve a pathologic complete response to treatment.\\\"\", \"\\\"pCR rate refers to the percentage of patients achieving a pathologic complete response in breast cancer treatment.\\\"\", \"\\\"pCR rate refers to the percentage of patients achieving a pathologic complete response.\\\"\", \"\\\"pCR rate refers to the percentage of patients who achieve a pathologic complete response after treatment.\\\"\", \"\\\"pCR rate refers to the percentage of patients who achieve a pathologic complete response.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.865s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.865s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"RESPONSE RATE\\\"\"\nDescription List: [\"\\\"Response rate refers to the percentage of participants who respond to a treatment.\\\"\", \"\\\"Response rate refers to the percentage of patients responding to treatment.\\\"\", \"\\\"response rate is a concept or marker that is associated with the effectiveness of treatment.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.863s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.863s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"KATERINE TRIAL\\\"\"\nDescription List: [\"\\\"KATERINE trial is a clinical trial evaluating adjuvant therapy in patients with HER2+ breast cancer.\\\"\", \"\\\"KATERINE trial is a clinical trial investigating the use of adjuvant T-DM1 in HER2+ IBC cases without a pCR.\\\"\", \"\\\"KATERINE trial is a clinical trial that recommended adjuvant T-DM1 in HER2+ IBC cases without a pCR.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.65s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.65s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"BEVERLY-2\\\"\"\nDescription List: [\"\\\"BEVERLY-2 is a clinical trial for breast cancer treatment.\\\"\", \"\\\"BEVERLY-2 is a study evaluating the pCR rate in non-metastatic IBC patients with HER2+ disease.\\\"\", \"\\\"BEVERLY-2 is a study mentioned in the text.\\\"\", \"\\\"BEVERLY-2 is a study on inflammatory breast cancer.\\\"\", \"\\\"BEVERLY-2 is a study that evaluated the pCR rate in non-metastatic IBC patients with HER2+ disease.\\\"\", \"\\\"BEVERLY-2 is a study that reported on the use of circulating tumor cells as a biomarker for treatment effectiveness.\\\"\", \"\\\"BEVERLY-2 is an event where a study on pathological response and circulating tumor cell count identifies treated HER2+ inflammatory breast cancer patients with excellent prognosis was conducted.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.583s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.583s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"BEVERLY-1\\\"\"\nDescription List: [\"\\\"BEVERLY-1 is a clinical trial for breast cancer treatment.\\\"\", \"\\\"BEVERLY-1 is a single-arm phase 2 study that evaluated the pCR rate in non-metastatic IBC patients with HER2- disease.\\\"\", \"\\\"BEVERLY-1 is a study evaluating the pCR rate in non-metastatic IBC patients with HER2- disease.\\\"\", \"\\\"BEVERLY-1 is a study mentioned in the text.\\\"\", \"\\\"BEVERLY-1 is a study that reported on the use of circulating tumor cells as a biomarker for treatment effectiveness.\\\"\", \"\\\"BEVERLY-1 is an event where a study on bevacizumab plus neoadjuvant chemotherapy in patients with HER2-negative inflammatory breast cancer was conducted.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.545s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.545s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"TCHP REGIMEN\\\"\"\nDescription List: [\"\\\"TCHP regimen is a chemotherapy regimen that includes trastuzumab and pertuzumab.\\\"\", \"\\\"TCHP regimen is a type of chemotherapy regimen used to treat breast cancer.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.468999999s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.468999999s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"GEPARQUINTO\\\"\"\nDescription List: [\"\\\"GeparQuinto is a clinical trial studying the effectiveness of neoadjuvant chemotherapy with trastuzumab or lapatinib in patients with human epidermal growth factor receptor 2-positive breast cancer.\\\"\", \"\\\"GeparQuinto is a clinical trial that investigated lapatinib versus trastuzumab in combination with neoadjuvant chemotherapy.\\\"\", \"\\\"GeparQuinto is a randomized neoadjuvant phase 3 trial.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.371s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.371s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"LAPATINIB\\\"\"\nDescription List: [\"\", \"\\\"Lapatinib is a drug used in combination with Pazopanib therapy.\\\"\", \"\\\"Lapatinib is a small-molecule tyrosine kinase inhibitor that blocks intracellular HER2 and EG.\\\"\", \"\\\"Lapatinib is a small-molecule tyrosine kinase inhibitor that blocks intracellular HER2 and EGFR signaling pathways.\\\"\", \"\\\"Lapatinib is an antibody-drug conjugate used in breast cancer treatment.\\\"\", \"\\\"lapatinib is a medication used in cancer treatment.\\\"\", \"\\\"lapatinib is a targeted therapy used to treat cancer.\\\"\", \"\\\"lapatinib is a treatment option for IBC, used in combination with NAC and trastuzumab.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.198s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.198s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"NERATINIB\\\"\"\nDescription List: [\"\\\"Neratinib is a medication used in adjuvant therapy for high-risk recurrent disease like IBC.\\\"\", \"\\\"Neratinib is a medication used in cancer treatment.\\\"\\\"Neratinib is offered as a treatment option.\\\"\", \"\\\"Neratinib is a medication used in the treatment of breast cancer.\\\"\", \"\\\"Neratinib is a medication used to treat HER2+ breast cancer, especially in high-risk situations.\\\"\", \"\\\"Neratinib is a treatment for HER2-positive breast cancer.\\\"\", \"\\\"neratinib is a chemotherapy drug.\\\"\", \"\\\"neratinib is a tyrosine kinase inhibitor used in clinical trials.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.194s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.194s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"DIARRHEA\\\"\"\nDescription List: [\"\\\"Diarrhea is a common side effect of a medication.\\\"\", \"\\\"Diarrhea is a type of serious adverse event that is associated with chemotherapy.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.105s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.105s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"S. CHAINITIKUN ET AL.\\\"\"\nDescription List: [\"\\\"S. Chainitikun et al. are the authors of the article published in the Journal of Advanced Research.\\\"\", \"\\\"S. Chainitikun et al. are the authors of the study.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.015s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.015s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"TAXANE-BASED CHEMOTHERAPY\\\"\"\nDescription List: [\"\\\"Taxane-based Chemotherapy is a type of chemotherapy used in the treatment of IBC.\\\"\", \"\\\"Taxane-based chemotherapy is a type of chemotherapy used in the treatment of IBC.\\\"\", \"\\\"Taxane-based chemotherapy is used in combination with Bevacizumab to inhibit tumor growth and metastasis.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 798ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 798ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"KRISTINE TRIAL\\\"\"\nDescription List: [\"\\\"KRISTINE trial is a randomized phase 3 trial evaluating neoadjuvant treatment with T-DM1 plus pertuzumab.\\\"\", \"\\\"The KRISTINE trial is a randomized phase 3 trial that evaluated the efficacy of T-DM1 plus pertuzumab in patients with HER2+ breast cancer.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.527s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.527s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"DFS\\\"\"\nDescription List: [\"\\\"DFS is a measure of disease-free survival in breast cancer patients.\\\"\", \"\\\"DFS is a measure of disease-free survival, a clinical outcome in breast cancer.\\\"\", \"\\\"DFS is a measure of the duration of survival after treatment for cancer.\\\"\", \"\\\"DFS is a term used in the studies to describe disease-free survival.\\\"\", \"\\\"DFS refers to the disease-free survival rate in IBC patients.\\\"\", \"\\\"DFS stands for disease-free survival, a measure of cancer treatment effectiveness.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.499s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.499s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"BEVERLY-1\\\"\"\nDescription List: [\"\\\"BEVERLY-1 is a clinical trial for breast cancer treatment.\\\"\", \"\\\"BEVERLY-1 is a single-arm phase 2 study that evaluated the pCR rate in non-metastatic IBC patients with HER2- disease.\\\"\", \"\\\"BEVERLY-1 is a study evaluating the pCR rate in non-metastatic IBC patients with HER2- disease.\\\"\", \"\\\"BEVERLY-1 is a study mentioned in the text.\\\"\", \"\\\"BEVERLY-1 is a study that reported on the use of circulating tumor cells as a biomarker for treatment effectiveness.\\\"\", \"\\\"BEVERLY-1 is an event where a study on bevacizumab plus neoadjuvant chemotherapy in patients with HER2-negative inflammatory breast cancer was conducted.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.431s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.431s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"BEVACIZUMAB\\\"\"\nDescription List: [\"\", \"\\\"Bevacizumab is a medication used in combination with chemotherapy to treat breast cancer.\\\"\", \"\\\"Bevacizumab is a monoclonal antibody against VEGF, used in combination with taxane-based chemotherapy to inhibit tumor growth and metastasis.\\\"\", \"\\\"Bevacizumab is a targeted therapy mentioned in the studies.\\\"\", \"\\\"Bevacizumab is a targeted therapy used in combination with chemotherapy for IBC patients.\\\"\", \"\\\"Bevacizumab is a technology used in the treatment of breast cancer and was studied in the presented research.\\\"\", \"\\\"Bevacizumab is a type of cancer treatment.\\\"\", \"\\\"Bevacizumab is a type of medication used in cancer treatment.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.558s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.558s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"CARBOPLATIN\\\"\"\nDescription List: [\"\\\"Carboplatin is a chemotherapy agent used in the treatment of IBC.\\\"\", \"\\\"Carboplatin is a chemotherapy drug used in breast cancer treatment.\\\"\", \"\\\"Carboplatin is a chemotherapy drug used in combination with other medications.\\\"\", \"\\\"Carboplatin is a chemotherapy drug used in the treatment of breast cancer.\\\"\", \"\\\"Carboplatin is a type of cancer treatment.\\\"\", \"\\\"Carboplatin is a type of chemotherapy used in the treatment of IBC.\\\"\", \"\\\"Carboplatin is a type of medication used in cancer treatment.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.069s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.069s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"TAXANE-BASED CHEMOTHERAPY\\\"\"\nDescription List: [\"\\\"Taxane-based Chemotherapy is a type of chemotherapy used in the treatment of IBC.\\\"\", \"\\\"Taxane-based chemotherapy is a type of chemotherapy used in the treatment of IBC.\\\"\", \"\\\"Taxane-based chemotherapy is used in combination with Bevacizumab to inhibit tumor growth and metastasis.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.939s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.939s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"BEVERLY-1\\\"\"\nDescription List: [\"\\\"BEVERLY-1 is a clinical trial for breast cancer treatment.\\\"\", \"\\\"BEVERLY-1 is a single-arm phase 2 study that evaluated the pCR rate in non-metastatic IBC patients with HER2- disease.\\\"\", \"\\\"BEVERLY-1 is a study evaluating the pCR rate in non-metastatic IBC patients with HER2- disease.\\\"\", \"\\\"BEVERLY-1 is a study mentioned in the text.\\\"\", \"\\\"BEVERLY-1 is a study that reported on the use of circulating tumor cells as a biomarker for treatment effectiveness.\\\"\", \"\\\"BEVERLY-1 is an event where a study on bevacizumab plus neoadjuvant chemotherapy in patients with HER2-negative inflammatory breast cancer was conducted.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.726999999s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.726999999s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"CARBOPLATIN\\\"\"\nDescription List: [\"\\\"Carboplatin is a chemotherapy agent used in the treatment of IBC.\\\"\", \"\\\"Carboplatin is a chemotherapy drug used in breast cancer treatment.\\\"\", \"\\\"Carboplatin is a chemotherapy drug used in combination with other medications.\\\"\", \"\\\"Carboplatin is a chemotherapy drug used in the treatment of breast cancer.\\\"\", \"\\\"Carboplatin is a type of cancer treatment.\\\"\", \"\\\"Carboplatin is a type of chemotherapy used in the treatment of IBC.\\\"\", \"\\\"Carboplatin is a type of medication used in cancer treatment.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.569s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.569s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"ORAL CYCLOPHOSPHAMIDE\\\"\"\nDescription List: [\"\\\"Oral cyclophosphamide is a chemotherapy drug used in combination with other medications.\\\"\", \"\\\"Oral cyclophosphamide is a type of medication used in cancer treatment.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.418s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.418s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": {"input": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\n\n#######\n-Data-\nEntities: \"\\\"ANTHRACYCLINE-CONTAINING REGIMEN\\\"\"\nDescription List: [\"\\\"Anthracycline-containing regimen is a treatment protocol for breast cancer.\\\"\", \"\\\"Anthracycline-containing regimen is a type of chemotherapy regimen used to treat breast cancer.\\\"\", \"\\\"Anthracycline-containing regimen is a type of chemotherapy that is used to treat HER2+ IBC.\\\"\", \"\\\"anthracycline-containing regimen is a type of treatment for HER2+ IBC.\\\"\"]\n#######\nOutput:\n"}}
{"type": "error", "data": "Error executing verb \"summarize_descriptions\" in create_summarized_entities: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.418s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datashaper\\workflow\\workflow.py\", line 415, in _execute_verb\n    result = await result\n             ^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\description_summarize.py\", line 183, in summarize_descriptions\n    results = [\n              ^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\description_summarize.py\", line 184, in <listcomp>\n    await get_resolved_entities(row, semaphore) for row in output.itertuples()\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\description_summarize.py\", line 147, in get_resolved_entities\n    results = await asyncio.gather(*futures)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n    future.result()\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\tasks.py\", line 267, in __step\n    result = coro.send(None)\n             ^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\description_summarize.py\", line 167, in do_summarize_descriptions\n    results = await strategy_exec(\n              ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\strategies\\graph_intelligence\\run_graph_intelligence.py\", line 34, in run\n    return await run_summarize_descriptions(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\strategies\\graph_intelligence\\run_graph_intelligence.py\", line 67, in run_summarize_descriptions\n    result = await extractor(items=items, descriptions=descriptions)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\summarize\\description_summary_extractor.py\", line 73, in __call__\n    result = await self._summarize_descriptions(items, descriptions)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\summarize\\description_summary_extractor.py\", line 106, in _summarize_descriptions\n    result = await self._summarize_descriptions_with_llm(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\summarize\\description_summary_extractor.py\", line 125, in _summarize_descriptions_with_llm\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\_asyncio.py\", line 71, in __anext__\n    do = self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py\", line 325, in iter\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py\", line 158, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.418s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.418s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": null}
{"type": "error", "data": "Error running pipeline!", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\run.py\", line 323, in run_pipeline\n    result = await workflow.run(context, callbacks)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datashaper\\workflow\\workflow.py\", line 369, in run\n    timing = await self._execute_verb(node, context, callbacks)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datashaper\\workflow\\workflow.py\", line 415, in _execute_verb\n    result = await result\n             ^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\description_summarize.py\", line 183, in summarize_descriptions\n    results = [\n              ^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\description_summarize.py\", line 184, in <listcomp>\n    await get_resolved_entities(row, semaphore) for row in output.itertuples()\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\description_summarize.py\", line 147, in get_resolved_entities\n    results = await asyncio.gather(*futures)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n    future.result()\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\tasks.py\", line 267, in __step\n    result = coro.send(None)\n             ^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\description_summarize.py\", line 167, in do_summarize_descriptions\n    results = await strategy_exec(\n              ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\strategies\\graph_intelligence\\run_graph_intelligence.py\", line 34, in run\n    return await run_summarize_descriptions(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\verbs\\entities\\summarize\\strategies\\graph_intelligence\\run_graph_intelligence.py\", line 67, in run_summarize_descriptions\n    result = await extractor(items=items, descriptions=descriptions)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\summarize\\description_summary_extractor.py\", line 73, in __call__\n    result = await self._summarize_descriptions(items, descriptions)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\summarize\\description_summary_extractor.py\", line 106, in _summarize_descriptions\n    result = await self._summarize_descriptions_with_llm(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\summarize\\description_summary_extractor.py\", line 125, in _summarize_descriptions_with_llm\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\_asyncio.py\", line 71, in __anext__\n    do = self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py\", line 325, in iter\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py\", line 158, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1289, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Pesankar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.418s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01j1m7ha6hevrb19g7knxdmps3` on requests per minute (RPM): Limit 30, Used 30, Requested 1. Please try again in 1.418s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'requests', 'code': 'rate_limit_exceeded'}}", "details": null}
